{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4000bc38-4e06-4da5-84c1-4753b8dbd9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab8f9c42-6b29-47f5-bf5b-eac0e75a9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def calculate_inception_score(images, classifier, batch_size=32, splits=10):\n",
    "    \"\"\"\n",
    "    Computes the Inception Score (IS) for generated images using a given classifier.\n",
    "\n",
    "    Parameters:\n",
    "        images (numpy.ndarray): \n",
    "            Generated images with shape (N, H, W, C). \n",
    "            For example, MNIST, FASION: (N, 28, 28, 1), CIFAR: (N, 32, 32, 3).\n",
    "        classifier (tf.keras.Model): \n",
    "            A pretrained classifier (e.g., Inception-V3 for CIFAR or a CNN for MNIST/Fashion-MNIST).\n",
    "        batch_size (int): \n",
    "            Batch size for model predictions.\n",
    "        splits (int): \n",
    "            Number of splits for IS computation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (mean_inception_score, std_inception_score)\n",
    "    \"\"\"\n",
    "    # Determine the expected number of channels and spatial dimensions from the classifier's input shape.\n",
    "    # classifier.input_shape is generally like (None, H_expected, W_expected, C_expected)\n",
    "    expected_height, expected_width, expected_channels = classifier.input_shape[1:4]\n",
    "\n",
    "    # Adjust the channel dimension if needed:\n",
    "    if images.shape[-1] != expected_channels:\n",
    "        if images.shape[-1] == 1 and expected_channels == 3:\n",
    "            images = np.repeat(images, 3, axis=-1)\n",
    "        elif images.shape[-1] == 3 and expected_channels == 1:\n",
    "            images = np.mean(images, axis=-1, keepdims=True)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Incompatible channel dimensions: images have {images.shape[-1]} channels, but classifier expects {expected_channels}.\"\n",
    "            )\n",
    "\n",
    "    # Normalize images to [0, 1] if they are not already\n",
    "    if images.max() > 1:\n",
    "        images = images.astype(np.float32) / 255.0\n",
    "\n",
    "    # Resize images if their spatial dimensions don't match the classifier's expected dimensions.\n",
    "    if images.shape[1] != expected_height or images.shape[2] != expected_width:\n",
    "        # Convert images to a TensorFlow tensor, resize, then convert back to numpy.\n",
    "        images = tf.image.resize(images, (expected_height, expected_width)).numpy()\n",
    "\n",
    "    num_images = images.shape[0]\n",
    "    preds = []\n",
    "\n",
    "    # Process images in batches.\n",
    "    for i in range(0, num_images, batch_size):\n",
    "        batch = images[i : i + batch_size]\n",
    "        # Get classifier predictions (logits)\n",
    "        logits = classifier.predict(batch, verbose=0)\n",
    "        # Convert logits to probabilities via softmax\n",
    "        prob = tf.nn.softmax(logits).numpy()\n",
    "        preds.append(prob)\n",
    "        \n",
    "    preds = np.concatenate(preds, axis=0)  # Shape: (N, num_classes)\n",
    "\n",
    "    # Compute the Inception Score using KL divergence\n",
    "    split_scores = []\n",
    "    split_size = num_images // splits\n",
    "    for i in range(splits):\n",
    "        part = preds[i * split_size : (i + 1) * split_size]\n",
    "        p_y = np.mean(part, axis=0)  # Marginal distribution over classes\n",
    "        kl_divs = [entropy(p, p_y) for p in part]\n",
    "        split_score = np.exp(np.mean(kl_divs))\n",
    "        split_scores.append(split_score)\n",
    "    \n",
    "    return np.mean(split_scores), np.std(split_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a24b1ab-434d-4974-b3b1-18428a873ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def train_mnist_classifier(epochs=5, batch_size=128):\n",
    "    # Load the MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Expand dimensions to include the channel (MNIST images are 28x28, grayscale)\n",
    "    x_train = np.expand_dims(x_train, axis=-1)\n",
    "    x_test = np.expand_dims(x_test, axis=-1)\n",
    "    \n",
    "    # Normalize the images to [0, 1]\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Convert labels to one-hot vectors\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "    \n",
    "    # Build a simple CNN model\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        # Final Dense layer without activation since we use logits\n",
    "        layers.Dense(10)\n",
    "    ])\n",
    "    \n",
    "    # Compile the model with the loss function expecting logits (from_logits=True)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=epochs, \n",
    "              batch_size=batch_size, \n",
    "              validation_data=(x_test, y_test))\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train the MNIST classifier\n",
    "# mnist_classifier = train_mnist_classifier(epochs=5)\n",
    "\n",
    "# Optionally, save the model if you'd like to reuse it later:\n",
    "# mnist_classifier.save(\"mnist_cnn_model.h5\")\n",
    "# mnist_classifier = tf.keras.models.load_model(\"mnist_cnn_model.h5\")  # Example path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abe5bd8c-1bc9-446f-83d0-808599df6dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception Score: 1.1078 ± 0.0072\n"
     ]
    }
   ],
   "source": [
    "# Load a trained CNN classifier for MNIST\n",
    "generated_mnist_images = np.random.rand(1000, 28, 28, 1)  # Fake grayscale images\n",
    "\n",
    "mean_is, std_is = calculate_inception_score(generated_mnist_images, mnist_classifier)\n",
    "print(f\"Inception Score: {mean_is:.4f} ± {std_is:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5aed791-0542-4569-81b5-96d82d08a30d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 35 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021505A11EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Inception Score: 1.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained InceptionV3 model (trained on ImageNet)\n",
    "inception_model = tf.keras.applications.InceptionV3(weights=\"imagenet\", include_top=True)\n",
    "generated_cifar_images = np.random.rand(20, 32, 32, 3)  # Fake CIFAR images\n",
    "\n",
    "mean_is, std_is = calculate_inception_score(generated_cifar_images, inception_model)\n",
    "print(f\"Inception Score: {mean_is:.4f} ± {std_is:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47cd3f0-6b97-46e9-9be0-44eab7465f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'analyze_created_images.ipynb',\n",
       " 'analyze_created_labels.ipynb',\n",
       " 'check_datasets.ipynb',\n",
       " 'ConditionalGAN.ipynb',\n",
       " 'models',\n",
       " 'n-mad-gan.ipynb',\n",
       " 'test_FID_score.ipynb',\n",
       " 'test_inception_score.ipynb',\n",
       " 'vanilla_gan_test']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.listdir('./../code/experiments/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
