{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5300d3-31e5-4e4d-aeb3-88007fb31edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def load_real_images(dataset, num_samples=10000):\n",
    "    \"\"\"Loads real images from MNIST, Fashion-MNIST, or CIFAR-10.\"\"\"\n",
    "    if dataset == \"mnist\":\n",
    "        (x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "        x_train = np.expand_dims(x_train, axis=-1)  # Add channel dimension\n",
    "    elif dataset == \"fashion-mnist\":\n",
    "        (x_train, _), _ = tf.keras.datasets.fashion_mnist.load_data()\n",
    "        x_train = np.expand_dims(x_train, axis=-1)  # Add channel dimension\n",
    "    elif dataset == \"cifar10\":\n",
    "        (x_train, _), _ = tf.keras.datasets.cifar10.load_data()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset}\")\n",
    "\n",
    "    x_train = x_train.astype(np.float32) / 255.0\n",
    "    idx = np.random.choice(len(x_train), num_samples, replace=False)\n",
    "    return x_train[idx]\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.linalg import sqrtm\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "def calculate_fid_score(generated_images, dataset, classifier, batch_size=32):\n",
    "    \"\"\"\n",
    "    Computes the FrÃ©chet Inception Distance (FID) between generated and real images.\n",
    "\n",
    "    Parameters:\n",
    "        generated_images (numpy.ndarray): Generated images with shape (N, H, W, C).\n",
    "        dataset (str): One of [\"mnist\", \"fashion-mnist\", \"cifar10\"].\n",
    "        classifier (tf.keras.Model): Model for feature extraction.\n",
    "                                   For CIFAR-10, use InceptionV3 (include_top=False, pooling=\"avg\").\n",
    "        batch_size (int): Batch size for inference.\n",
    "\n",
    "    Returns:\n",
    "        float: FID score (lower is better).\n",
    "    \"\"\"\n",
    "    # Load real images for the chosen dataset\n",
    "    real_images = load_real_images(dataset)\n",
    "\n",
    "    # Determine expected input shape\n",
    "    input_shape = classifier.input.shape.as_list()  # e.g., [None, 299, 299, 3] or [None, 28, 28, 1]\n",
    "    expected_height, expected_width, expected_channels = input_shape[1], input_shape[2], input_shape[3]\n",
    "\n",
    "    # Set defaults if input shape is undefined\n",
    "    if expected_height is None or expected_width is None or expected_channels is None:\n",
    "        if dataset == \"cifar10\":\n",
    "            expected_height, expected_width, expected_channels = 299, 299, 3\n",
    "        elif dataset in [\"mnist\", \"fashion-mnist\"]:\n",
    "            expected_height, expected_width, expected_channels = 28, 28, 1\n",
    "\n",
    "    # Adjust channel dimension if needed\n",
    "    if generated_images.shape[-1] != expected_channels:\n",
    "        if generated_images.shape[-1] == 1 and expected_channels == 3:\n",
    "            generated_images = np.repeat(generated_images, 3, axis=-1)\n",
    "        elif generated_images.shape[-1] == 3 and expected_channels == 1:\n",
    "            generated_images = np.mean(generated_images, axis=-1, keepdims=True)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Incompatible channel dimensions: images have {generated_images.shape[-1]} channels, but classifier expects {expected_channels}.\"\n",
    "            )\n",
    "\n",
    "    # Normalize generated images if needed (assuming pixel range [0,255])\n",
    "    if generated_images.max() > 1:\n",
    "        generated_images = generated_images.astype(np.float32) / 255.0\n",
    "\n",
    "    # Resize images on CPU to avoid GPU memory overflow\n",
    "    if (generated_images.shape[1] != expected_height) or (generated_images.shape[2] != expected_width):\n",
    "        resize_shape = [int(expected_height), int(expected_width)]\n",
    "        with tf.device('/CPU:0'):\n",
    "            generated_images = tf.image.resize(generated_images, resize_shape).numpy()\n",
    "            real_images = tf.image.resize(real_images, resize_shape).numpy()\n",
    "\n",
    "    # Apply preprocessing for InceptionV3 (CIFAR-10 case)\n",
    "    if dataset == \"cifar10\":\n",
    "        generated_images = preprocess_input(generated_images * 255.0)\n",
    "        real_images = preprocess_input(real_images * 255.0)\n",
    "\n",
    "    # Extract features from an intermediate layer\n",
    "    if dataset != \"cifar10\":\n",
    "        assert(\"global_average_pooling2d\" in [l.name for l in classifier.layers])\n",
    "        feature_extractor = tf.keras.Model(classifier.input, classifier.get_layer('global_average_pooling2d').output)\n",
    "    else: \n",
    "        # we assume the following definition for the classifier of the inception model: \n",
    "        # classifier = tf.keras.applications.InceptionV3(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "        feature_extractor = classifier \n",
    "        classifier = None \n",
    "\n",
    "    # Define a helper function to extract features in batches\n",
    "    def get_features(images):\n",
    "        features = []\n",
    "        for i in range(0, images.shape[0], batch_size):\n",
    "            batch = images[i : i + batch_size]\n",
    "            feat = feature_extractor.predict(batch, verbose=0)\n",
    "            features.append(feat)\n",
    "        return np.concatenate(features, axis=0)\n",
    "\n",
    "    real_features = get_features(real_images)\n",
    "    generated_features = get_features(generated_images)\n",
    "\n",
    "    # Compute mean and covariance statistics\n",
    "    mu_real, sigma_real = real_features.mean(axis=0), np.cov(real_features, rowvar=False)\n",
    "    mu_gen, sigma_gen = generated_features.mean(axis=0), np.cov(generated_features, rowvar=False)\n",
    "\n",
    "    # Compute squared difference between means\n",
    "    diff = mu_real - mu_gen\n",
    "    diff_squared = diff.dot(diff)\n",
    "\n",
    "    # Compute sqrt of the product of covariance matrices\n",
    "    covmean, _ = sqrtm(sigma_real.dot(sigma_gen), disp=False)\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real  # Numerical stability fix\n",
    "\n",
    "    # Compute final FID score\n",
    "    fid = diff_squared + np.trace(sigma_real + sigma_gen - 2 * covmean)\n",
    "    return fid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd95b481-ad6b-4a2c-b63d-2fa2fd30b8bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 606.6148\n",
      "FID Score: 31.7631\n"
     ]
    }
   ],
   "source": [
    "# Specify dataset and load the appropriate classifier.\n",
    "dataset = \"cifar10\"\n",
    "classifier = tf.keras.applications.InceptionV3(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "\n",
    "# Generate some dummy CIFAR images.\n",
    "generated_images = np.random.rand(1000, 32, 32, 3).astype(np.float32)\n",
    "\n",
    "(cifar_sample_images, _), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "cifar_sample_images = cifar_sample_images[:1_000]\n",
    "\n",
    "fid_score = calculate_fid_score(generated_images, dataset, classifier)\n",
    "print(f\"FID Score: {fid_score:.4f}\")\n",
    "\n",
    "\n",
    "fid_score = calculate_fid_score(cifar_sample_images, dataset, classifier)\n",
    "print(f\"FID Score: {fid_score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23adf8a9-c748-4be2-90ec-ef2c7c58e0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 images with shape (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def load_images_from_folder(folder_path, target_size=(32, 32)):\n",
    "    \"\"\"\n",
    "    Loads all images from a specified folder into a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "        target_size (tuple): Desired image size (height, width).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array of images with shape (N, H, W, C).\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path)[:500]:\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            img = load_img(img_path, target_size=target_size)  # Load and resize image\n",
    "            img_array = img_to_array(img) / 255.0  # Convert to array and normalize\n",
    "            images.append(img_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load image {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "# Example Usage\n",
    "folder_path = \"./../code/experiments/2025-02-03_generative_creation_test_cifar10/generated_images\"  # Replace with your actual folder path\n",
    "loaded_images = load_images_from_folder(folder_path, target_size=(32, 32))\n",
    "print(f\"Loaded {loaded_images.shape[0]} images with shape {loaded_images.shape[1:]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d0996b-16f6-4bd6-af4f-ddc55658e9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 87.0484\n"
     ]
    }
   ],
   "source": [
    "fid_score = calculate_fid_score(loaded_images, dataset, classifier)\n",
    "print(f\"FID Score: {fid_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "015fe31d-b2df-4aee-b4f2-7d9a5de0cdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_97 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,474\n",
      "Trainable params: 110,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3320 - accuracy: 0.8915 - val_loss: 0.1101 - val_accuracy: 0.9647\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0954 - accuracy: 0.9705 - val_loss: 0.0619 - val_accuracy: 0.9812\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0646 - accuracy: 0.9804 - val_loss: 0.0401 - val_accuracy: 0.9865\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0494 - accuracy: 0.9842 - val_loss: 0.0451 - val_accuracy: 0.9865\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 0.0352 - val_accuracy: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20104faf550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_classifier(input_shape=(32, 32, 3), num_classes=10):\n",
    "    \"\"\"\n",
    "    Creates a simple CNN classifier for MNIST, Fashion-MNIST, or CIFAR-10.\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): Shape of the input images, e.g., (32, 32, 3).\n",
    "        num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: A compiled CNN model.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.GlobalAveragePooling2D(name=\"global_average_pooling2d\"),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')  # Softmax for classification\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "classifier = create_classifier(input_shape=(28, 28, 1), num_classes=10)\n",
    "classifier.summary()\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "classifier.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7e2a8e-229a-4339-b4be-c9000c00cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 images with shape (28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example Usage\n",
    "folder_path = \"./../code/experiments/2025-02-12_MADGAN_MNIST_5_GEN_DataCreation_SPEC_GEN_4/generated_images\"  # Replace with your actual folder path\n",
    "loaded_images = load_images_from_folder(folder_path, target_size=(28, 28))\n",
    "print(f\"Loaded {loaded_images.shape[0]} images with shape {loaded_images.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596816fa-b470-45eb-8331-ab12a114fe87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 0.9705\n"
     ]
    }
   ],
   "source": [
    "fid_score = calculate_fid_score(loaded_images, dataset=\"mnist\", classifier=classifier)\n",
    "print(f\"FID Score: {fid_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956c551-b836-48c6-921c-96daee9696a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
