{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gen = 2  # number of generators\n",
    "latent_dim = 256  # dimention of input noise\n",
    "batch_size = 256  # number of batches\n",
    "size_dataset = 60_000  # size MNIST dataset - 60_000\n",
    "epochs = 2\n",
    "steps_per_epoch = (size_dataset // batch_size) // n_gen\n",
    "type = \"no-stack\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "dir_name = f\"models/MNIST_{n_gen}-gen_{epochs}-ep_{type}-type_{current_date}\"  # location to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists at: models/MNIST_2-gen_2-ep_no-stack-type_2024-12-05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if the folder exists, if not, create it\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "    print(f\"Folder created at: {dir_name}\")\n",
    "else:\n",
    "    print(f\"Folder already exists at: {dir_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    LeakyReLU,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Flatten,\n",
    "    Reshape,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Done\n"
     ]
    }
   ],
   "source": [
    "# for saving GIF\n",
    "\n",
    "print(\"Import Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To see if we have a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Using a GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "\n",
    "if tf.test.gpu_device_name() == \"/device:GPU:0\":\n",
    "    print(\"Using a GPU\")\n",
    "else:\n",
    "    print(\"Using a CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPUs available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquire dataset MNIST\n",
    "## generate latent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = (\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of data\")\n",
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability import distributions as tfd\n",
    "\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, batch_size, n_gen):\n",
    "    # Multivariate normal diagonal distribution\n",
    "    mvn = tfd.MultivariateNormalDiag(\n",
    "        loc=[0] * latent_dim, scale_diag=[1.0] * latent_dim\n",
    "    )\n",
    "\n",
    "    noise = []\n",
    "    for i in range(n_gen):\n",
    "        # Some samples from MVN\n",
    "        x_input = mvn.sample(batch_size)\n",
    "        noise.append(x_input)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generator related\n",
    "## monitor, loss\n",
    "## plotting funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to create a GIF from a list of image paths\n",
    "def create_gif(image_folder, output_gif, duration=500):\n",
    "    image_files = sorted(\n",
    "        [\n",
    "            os.path.join(image_folder, file)\n",
    "            for file in os.listdir(image_folder)\n",
    "            if file.endswith(\".png\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    frames = []\n",
    "    for image_name in image_files:\n",
    "        img = Image.open(image_name)\n",
    "        frames.append(img)\n",
    "\n",
    "    # Save the frames as an animated GIF\n",
    "    frames[0].save(\n",
    "        output_gif,\n",
    "        format=\"GIF\",\n",
    "        append_images=frames[1:],\n",
    "        save_all=True,\n",
    "        duration=duration,\n",
    "        loop=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, save: bool = True):\n",
    "    # Extract losses from history\n",
    "    history_dict = history.history\n",
    "    generator_losses = []\n",
    "    discriminator_loss = None\n",
    "\n",
    "    # Separate generator losses and discriminator loss\n",
    "    for key in history_dict.keys():\n",
    "        if \"g_loss\" in key:\n",
    "            generator_losses.append((key, history_dict[key]))\n",
    "        elif key == \"d_loss\":\n",
    "            discriminator_loss = history_dict[key]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot generator losses\n",
    "    for gen_loss_key, gen_loss_values in generator_losses:\n",
    "        plt.plot(gen_loss_values, label=gen_loss_key)\n",
    "\n",
    "    # Plot discriminator loss\n",
    "    if discriminator_loss is not None:\n",
    "        plt.plot(\n",
    "            discriminator_loss,\n",
    "            label=\"d_loss\",\n",
    "            linewidth=2,\n",
    "            linestyle=\"--\",\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "    plt.title(\"Training Losses\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    if save:\n",
    "        plt.savefig(\n",
    "            f\"{dir_name}/image_at_epoch_{(epoch + 1):04}.png\", dpi=200, format=\"png\"\n",
    "        )\n",
    "\n",
    "\n",
    "def plot_generators_examples(\n",
    "    n_rows: int,\n",
    "    n_cols: int,\n",
    "    random_latent_vectors: list,\n",
    "    data,\n",
    "    generators: list,\n",
    "    dir_name: str,\n",
    "    epoch: int,\n",
    "    save: bool = False,\n",
    "    show: bool = True,\n",
    ") -> None:\n",
    "    # Create a figure and a grid of subplots\n",
    "    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(12, 8))\n",
    "    fig.suptitle(f\"Epoch: {epoch}\", fontsize=20)\n",
    "    # Flatten the axes array to iterate over individual subplots\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Iterate over the subplots\n",
    "    for i, ax in enumerate(axes):\n",
    "        # Calculate the current row based on index\n",
    "        current_row = i // n_cols\n",
    "\n",
    "        # Determine if we're plotting real or generated data\n",
    "        if (i + 1) % n_cols == 0:\n",
    "            # Plot real data\n",
    "            if current_row < len(data):\n",
    "                ax.imshow(\n",
    "                    (\n",
    "                        data[\n",
    "                            current_row,\n",
    "                            :,\n",
    "                            :,\n",
    "                        ]\n",
    "                        * 127.5\n",
    "                        + 127.5\n",
    "                    )\n",
    "                    / 255,\n",
    "                    cmap=\"gray\",\n",
    "                )\n",
    "                ax.set_title(\"REAL\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Skipping real data plot for row {current_row}: Index out of bounds.\"\n",
    "                )\n",
    "        else:\n",
    "            # Plot generated data\n",
    "            generator_index = i % (n_cols - 1)\n",
    "            generated_sample = generators[generator_index](\n",
    "                random_latent_vectors[generator_index]\n",
    "            )\n",
    "            ax.imshow(\n",
    "                (\n",
    "                    generated_sample[\n",
    "                        current_row,\n",
    "                        :,\n",
    "                        :,\n",
    "                    ]\n",
    "                    * 127.5\n",
    "                    + 127.5\n",
    "                )\n",
    "                / 255,\n",
    "                cmap=\"gray\",\n",
    "            )\n",
    "            ax.set_title(f\"FAKE (Gen {generator_index + 1})\")\n",
    "\n",
    "        # Turn off axis labels for clarity\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Adjust layout and spacing\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(\n",
    "            f\"{dir_name}/image_at_epoch_{(epoch + 1):04}.png\", dpi=200, format=\"png\"\n",
    "        )\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss function for the generators based on the MAD_GAN paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generators_loss_function(y_true, y_pred):\n",
    "    logarithm = -tf.math.log(y_pred[:, -1] + 1e-15)\n",
    "    return tf.reduce_mean(logarithm, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        random_latent_vectors,\n",
    "        data,\n",
    "        n_classes,\n",
    "        latent_dim=128,\n",
    "        dir_name=\"Model\",\n",
    "        generate_after_epochs: int = 10,\n",
    "    ):\n",
    "        self.data = data[0:10]\n",
    "        self.random_latent_vectors = random_latent_vectors\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dir_name = dir_name\n",
    "        self.n_classes = n_classes\n",
    "        self.generate_after_epochs = generate_after_epochs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.generate_after_epochs == 0:\n",
    "            plot_generators_examples(\n",
    "                n_rows=len(self.model.generators),\n",
    "                n_cols=len(self.model.generators) + 1,\n",
    "                dir_name=self.dir_name,\n",
    "                random_latent_vectors=self.random_latent_vectors,\n",
    "                data=self.data,\n",
    "                generators=self.model.generators,\n",
    "                epoch=epoch,\n",
    "                save=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define Discriminator \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator(n_gen):\n",
    "    inp = Input(shape=(28, 28, 1))\n",
    "\n",
    "    x = Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\", input_shape=[28, 28, 1])(inp)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    out = Dense(n_gen + 1, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inp, out, name=\"Discriminator\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12544"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 * 7 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generators(n_gen, latent_dim, class_labels):\n",
    "    dens = Dense(units=7 * 7 * 256, use_bias=False, input_shape=(latent_dim,))\n",
    "    batchnorm0 = BatchNormalization()\n",
    "    rel0 = LeakyReLU()\n",
    "    reshape0 = Reshape([7, 7, latent_dim])\n",
    "\n",
    "    con2dt1 = Conv2DTranspose(\n",
    "        128, (5, 5), strides=(1, 1), padding=\"same\", use_bias=False\n",
    "    )\n",
    "    batchnorm1 = BatchNormalization()\n",
    "    rel1 = LeakyReLU()\n",
    "\n",
    "    con2dt2 = Conv2DTranspose(\n",
    "        64, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False\n",
    "    )\n",
    "    batchnorm2 = BatchNormalization()\n",
    "    rel2 = LeakyReLU()\n",
    "\n",
    "    models = []\n",
    "    for label in range(n_gen):\n",
    "        input = Input(shape=(latent_dim,), dtype=tf.float64, name=f\"input_{label}\")\n",
    "        x = dens(input)\n",
    "        x = batchnorm0(x)\n",
    "        x = rel0(x)\n",
    "        x = reshape0(x)\n",
    "\n",
    "        x = con2dt1(x)\n",
    "        x = batchnorm1(x)\n",
    "        x = rel1(x)\n",
    "\n",
    "        x = con2dt2(x)\n",
    "        x = batchnorm2(x)\n",
    "        x = rel2(x)\n",
    "\n",
    "        x = Conv2DTranspose(\n",
    "            1, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False, activation=\"tanh\"\n",
    "        )(x)\n",
    "\n",
    "        models.append(Model(input, x, name=f\"generator{label}\"))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining the N-MAD GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MADGAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generators, latent_dim, n_gen):\n",
    "        super(MADGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generators = generators\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_gen = n_gen\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(MADGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        X = data\n",
    "\n",
    "        batch_size = tf.shape(X)[0]\n",
    "        random_latent_vectors = generate_latent_points(\n",
    "            self.latent_dim, batch_size // self.n_gen, self.n_gen\n",
    "        )\n",
    "        print(self.latent_dim, batch_size // self.n_gen, self.n_gen)\n",
    "        # Decode them to fake generator output\n",
    "        x_generator = []\n",
    "        for g in range(self.n_gen):\n",
    "            x_generator.append(self.generators[g](random_latent_vectors[g]))\n",
    "\n",
    "        # Combine them with real samples\n",
    "        combined_samples = tf.concat(\n",
    "            [x_generator[g] for g in range(self.n_gen)] + [X], axis=0\n",
    "        )\n",
    "        # Assemble labels discriminating real from fake samples\n",
    "        labels = tf.concat(\n",
    "            [\n",
    "                tf.one_hot(\n",
    "                    g * tf.ones(batch_size // self.n_gen, dtype=tf.int32),\n",
    "                    self.n_gen + 1,\n",
    "                )\n",
    "                for g in range(self.n_gen)\n",
    "            ]\n",
    "            + [\n",
    "                tf.one_hot(\n",
    "                    self.n_gen * tf.ones(batch_size, dtype=tf.int32), self.n_gen + 1\n",
    "                )\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        # Add random noise to the labels. important trick\n",
    "        labels += 0.05 * tf.random.uniform(shape=tf.shape(labels), minval=-1, maxval=1)\n",
    "\n",
    "        #######################\n",
    "        # Train Discriminator #\n",
    "        #######################\n",
    "\n",
    "        # make weights in the discriminator trainable\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Discriminator forward pass\n",
    "            predictions = self.discriminator(combined_samples)\n",
    "\n",
    "            # Compute the loss value\n",
    "            d_loss = self.d_loss_fn(labels, predictions)\n",
    "\n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        # Update weights\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        #######################\n",
    "        #   Train Generator   #\n",
    "        #######################\n",
    "\n",
    "        # Assemble labels that say are \"all real samples\" to try to fool the disc during gen training\n",
    "        misleading_labels = tf.one_hot(\n",
    "            self.n_gen * tf.ones(batch_size // self.n_gen, dtype=tf.int32),\n",
    "            self.n_gen + 1,\n",
    "        )\n",
    "        g_loss_list = []\n",
    "        fake_image = []\n",
    "\n",
    "        for g in range(self.n_gen):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generator[g] and discriminator forward pass\n",
    "                predictions = self.discriminator(\n",
    "                    self.generators[g](random_latent_vectors[g])\n",
    "                )\n",
    "\n",
    "                # Compute the loss value\n",
    "                g_loss = self.g_loss_fn(misleading_labels, predictions)\n",
    "\n",
    "            # Compute gradients\n",
    "            grads = tape.gradient(g_loss, self.generators[g].trainable_weights)\n",
    "            # Update weights\n",
    "            self.g_optimizer[g].apply_gradients(\n",
    "                zip(grads, self.generators[g].trainable_weights)\n",
    "            )\n",
    "            g_loss_list.append(g_loss)\n",
    "\n",
    "        mydict = {f\"g_loss{g}\": g_loss_list[g] for g in range(self.n_gen)}\n",
    "        mydict.update({\"d_loss\": d_loss})\n",
    "        return mydict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_func(random_state=None):\n",
    "    (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\n",
    "        \"float32\"\n",
    "    )\n",
    "    # train_images = tf.image.resize(train_images, [32,32])\n",
    "    train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "\n",
    "    # Convert to stacked-mnist(rgb images)\n",
    "    # t1 = tf.random.shuffle(train_images, seed = 10)\n",
    "    # t2 = tf.random.shuffle(train_images, seed = 20)\n",
    "    # train_images = tf.concat([train_images, t1, t2], axis=-1)\n",
    "\n",
    "    return train_images, np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 18819     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,411\n",
      "Trainable params: 225,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator0\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_0 (InputLayer)        [(None, 256)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12544)             3211264   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 12544)            50176     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 12544)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819200    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204800    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1600      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,287,808\n",
      "Trainable params: 4,262,336\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Changing numpy dataset to tf.DATASET type and Shuffling dataset for training\n",
    "data, unique_labels = dataset_func()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "dataset = (\n",
    "    dataset.repeat()\n",
    "    .shuffle(10 * size_dataset, reshuffle_each_iteration=True)\n",
    "    .batch(n_gen * batch_size, drop_remainder=True)\n",
    ")\n",
    "\n",
    "# Creating Discriminator and Generator\n",
    "discriminator = define_discriminator(n_gen)\n",
    "discriminator.summary()\n",
    "generators = define_generators(n_gen, latent_dim, class_labels=unique_labels)\n",
    "generators[0].summary()\n",
    "\n",
    "# creating MADGAN\n",
    "madgan = MADGAN(\n",
    "    discriminator=discriminator,\n",
    "    generators=generators,\n",
    "    latent_dim=latent_dim,\n",
    "    n_gen=n_gen,\n",
    ")\n",
    "\n",
    "madgan.compile(\n",
    "    d_optimizer=Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    g_optimizer=[Adam(learning_rate=1e-4, beta_1=0.5) for g in range(n_gen)],\n",
    "    d_loss_fn=CategoricalCrossentropy(),\n",
    "    g_loss_fn=Generators_loss_function,\n",
    ")\n",
    "\n",
    "checkpoint_filepath = f\"{dir_name}\\checkpoint.weights.h5\"\n",
    "random_latent_vectors = generate_latent_points(\n",
    "    latent_dim=latent_dim, batch_size=11, n_gen=n_gen\n",
    ")\n",
    "\n",
    "my_callbacks = [\n",
    "    GANMonitor(\n",
    "        random_latent_vectors=random_latent_vectors,\n",
    "        data=data,\n",
    "        n_classes=len(unique_labels),\n",
    "        latent_dim=latent_dim,\n",
    "        dir_name=dir_name,\n",
    "    ),\n",
    "    # This callback is for Saving the model\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath, save_freq=10, save_weights_only=True\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\NiXoN\\miniconda3\\envs\\local_thesis_conda\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:342: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n",
      "256 Tensor(\"floordiv_1:0\", shape=(), dtype=int32) 2\n",
      "256 Tensor(\"floordiv_1:0\", shape=(), dtype=int32) 2\n",
      "  6/117 [>.............................] - ETA: 7s - g_loss0: 1.0288 - g_loss1: 1.0049 - d_loss: 0.9203WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0138s vs `on_train_batch_end` time: 0.0475s). Check your callbacks.\n",
      "117/117 [==============================] - ETA: 0s - g_loss0: 3.1719 - g_loss1: 3.1629 - d_loss: 0.4334"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 16s 83ms/step - g_loss0: 3.1851 - g_loss1: 3.1761 - d_loss: 0.4327\n",
      "Epoch 2/2\n",
      "117/117 [==============================] - 9s 75ms/step - g_loss0: 5.1596 - g_loss1: 5.1565 - d_loss: 0.3598\n"
     ]
    }
   ],
   "source": [
    "# # Loading previous saved model for resume training\n",
    "# if os.path.exists(checkpoint_filepath):\n",
    "#     madgan.load_weights(checkpoint_filepath)\n",
    "#     print(f\"Continue to train model from path: {checkpoint_filepath}\")\n",
    "\n",
    "# train the model\n",
    "history = madgan.fit(\n",
    "    dataset,\n",
    "    epochs=2,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    verbose=1,\n",
    "    callbacks=my_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_gif(image_folder=dir_name, output_gif=dir_name + \"/output.gif\", duration=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((generators[0](random_latent_vectors[0]) * 127.5 + 127.5) / 127.5) * 255"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
