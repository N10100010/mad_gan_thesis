{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b69e24-1113-4675-9a99-09c1d33b3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,            # Use LaTeX for all text\n",
    "    \"font.family\": \"serif\",         # Use serif font\n",
    "    \"font.serif\": [\"Computer Modern Roman\"],  # LaTeX default\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"font.size\": 12,\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "})\n",
    "\n",
    "import os \n",
    "from pathlib import Path \n",
    "\n",
    "import re \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc56cdab-0314-497f-8789-1dc6d193bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"FASHION_MNIST_STRATIFIED_CLASSIFIERS_MADGAN\"\n",
    "# FOLDER = \"MNIST_STRATIFIED_CLASSIFIERS_MADGAN\"\n",
    "BASE_EXPERIMENT = \"2025-02-28_Stratified_classifierExperiment_FASHIONMNIST__BASE__images_real_5000_gen_0\"\n",
    "\n",
    "TYPE = \"MADGAN\"\n",
    "DATASET = \"FASHION\"\n",
    "\n",
    "metrics = [\"val_accuracy\", \"val_f1_score\", \"val_loss\"]\n",
    "\n",
    "base_path = Path(\"C:/Users/NiXoN/Desktop/_thesis/mad_gan_thesis/notebooks\")\n",
    "strat_exp_path = base_path / 'experiments' / FOLDER \n",
    "\n",
    "experiments = os.listdir(strat_exp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fc5b3d1-7f36-4ee4-9a9e-3ed890f1a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab10')  # good for distinct colors (up to 10)\n",
    "colors = [cmap(i) for i in range(10)] + [(0.5, 0.5, 0.5, 1.0)]  # Add gray for the 11th color\n",
    "\n",
    "color_dict_by_generator = {str(i): colors[i] for i in range(11)}\n",
    "\n",
    "\n",
    "def extract_info_from_experiment_name(exp: str) -> dict: \n",
    "    splt = exp.split('_')\n",
    "    ret = {'dataset': splt[3], 'n_gen': splt[5], 'used_gen': splt[8], 'n_real': splt[-3], 'n_fake': splt[-1]}\n",
    "    \n",
    "    if any([v == '' for v in ret.values()]): \n",
    "        print(\"ALARM\")\n",
    "        print(exp)\n",
    "\n",
    "    return ret\n",
    "\n",
    "def sort_dict_based_on_n_real_images(d: dict, reverse=True) -> dict: \n",
    "    return dict(sorted(\n",
    "        d.items(),\n",
    "        key=lambda x: int(re.search(r'images_real_(\\d+)', x[0]).group(1)), \n",
    "        reverse=reverse\n",
    "    ))\n",
    "\n",
    "\n",
    "def plot_history_strat_classifiers(histories: dict, meta_info: dict, save_path: Path, target_gen, METRIC, show: bool = False) -> None: \n",
    "    mi = {'': [100]}\n",
    "    ma = {'': [0]}\n",
    "    \n",
    "    all_vals = []\n",
    "    max_n_gen = 0 \n",
    "    min_n_gen = 100\n",
    "    baseline = None\n",
    "    for exp, hist in histories.items():\n",
    "\n",
    "        if exp == BASE_EXPERIMENT:\n",
    "            continue \n",
    "        \n",
    "        dataset, n_gen, used_gen, n_real, n_fake = meta_info[exp].values()\n",
    "        \n",
    "        n_gen_int = int(used_gen)\n",
    "        \n",
    "        plt.plot(\n",
    "            hist[METRIC], \n",
    "            color=(np.clip((int(n_gen_int) - 1) / (int(n_gen) - 1), 0, 1), 0, np.clip((int(n_gen_int) - 1) / (int(n_gen) - 1), 0, 1), .25)  # Light grey for individual runs\n",
    "        )\n",
    "        \n",
    "        all_vals.append(hist[METRIC])\n",
    "        \n",
    "        if hist[METRIC][-1] > list(ma.values())[-1][-1]: \n",
    "            ma = {exp: hist[METRIC]}\n",
    "            \n",
    "        if hist[METRIC][-1] < list(mi.values())[-1][-1]: \n",
    "            mi = {exp: hist[METRIC]}\n",
    "    \n",
    "    # Pad shorter histories for averaging\n",
    "    max_len = max(map(len, all_vals))\n",
    "    all_vals_padded = [np.pad(a, (0, max_len - len(a)), constant_values=np.nan) for a in all_vals]\n",
    "    \n",
    "    avg = np.nanmean(all_vals_padded, axis=0)\n",
    "    med = np.nanmedian(all_vals_padded, axis=0)\n",
    "    \n",
    "    # CUD color palette\n",
    "    color_min = '#D55E00'  # Rust (worst)\n",
    "    color_max = '#009E73'  # Teal (best)\n",
    "    color_avg = '#0072B2'  # Blue (average)\n",
    "    color_med = '#E69F00'  # Golden (median)\n",
    "    \n",
    "    # Plot min run\n",
    "    dataset, n_gen, used_gen, n_real, n_fake = meta_info[list(mi.keys())[0]].values()\n",
    "    plt.plot(list(mi.values())[-1], color=color_min, linewidth=2, label=f\"Minimum, gen: {used_gen}, N-real: {n_real}, N-fake: {n_fake}\")\n",
    "    \n",
    "    # Plot max run\n",
    "    dataset, n_gen, used_gen, n_real, n_fake = meta_info[list(ma.keys())[0]].values()\n",
    "    plt.plot(list(ma.values())[-1], color=color_max, linewidth=2, label=f\"Maximum, gen: {used_gen}, N-real: {n_real}, N-fake: {n_fake}\")\n",
    "    \n",
    "    # Plot average\n",
    "    plt.plot(avg, color=color_avg, linewidth=2, label=\"Average\")\n",
    "    \n",
    "    # Plot median\n",
    "    plt.plot(med, color=color_med, linewidth=2, linestyle='--', label=\"Median\")\n",
    "    \n",
    "    baseline_history = histories[BASE_EXPERIMENT]\n",
    "    plt.plot(baseline_history[METRIC], color=(0,0,0,.5), linewidth=2.5, label='Baseline' )\n",
    "    \n",
    "    plt.title(f\"Validation Accuracy - Dataset: {dataset}, N-Gen: {target_gen}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    if show:\n",
    "        print(show)\n",
    "        plt.show()\n",
    "    else: \n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a834b9e-d7f9-4706-8d59-2c909329c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Define BASE_EXPERIMENT somewhere accessible if not already defined globally\n",
    "# Example: BASE_EXPERIMENT = 'your_baseline_experiment_key'\n",
    "# Make sure BASE_EXPERIMENT exists as a key in the histories dictionary\n",
    "\n",
    "def plot_history_strat_classifiers(histories: dict, meta_info: dict, save_path: Path, target_gen, METRIC, show: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Plots the history of a given metric across multiple experiments,\n",
    "    highlighting the best and worst runs based on the final value,\n",
    "    and showing the average and median. Handles metrics where lower is better (e.g., val_loss).\n",
    "\n",
    "    Args:\n",
    "        histories (dict): Dictionary where keys are experiment identifiers and values are history objects (e.g., dicts containing lists of metrics per epoch).\n",
    "        meta_info (dict): Dictionary mapping experiment identifiers to metadata (e.g., {'dataset': 'MNIST', 'n_gen': '10', 'used_gen': '5', 'n_real': 1000, 'n_fake': 1000}).\n",
    "        save_path (Path): Path object where the plot image should be saved.\n",
    "        target_gen (str or int): The total number of generators for this set of experiments (used in title).\n",
    "        METRIC (str): The key for the metric to plot (e.g., \"val_accuracy\", \"val_loss\").\n",
    "        show (bool, optional): If True, display the plot instead of saving. Defaults to False.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6)) # Add figure size for better readability\n",
    "\n",
    "    # --- MODIFIED: Initialization for Best/Worst Tracking ---\n",
    "    best_run_key = None\n",
    "    best_run_hist = None\n",
    "    worst_run_key = None\n",
    "    worst_run_hist = None\n",
    "\n",
    "    # Initialize comparison values based on METRIC type\n",
    "    lower_is_better = METRIC == 'val_loss' # Add other metrics here if needed\n",
    "\n",
    "    if lower_is_better:\n",
    "        best_val = float('inf')  # Initialize best value to infinity (seeking minimum)\n",
    "        worst_val = float('-inf') # Initialize worst value to negative infinity (seeking maximum)\n",
    "    else: # For accuracy, f1_score, etc. (higher is better)\n",
    "        best_val = float('-inf') # Initialize best value to negative infinity (seeking maximum)\n",
    "        worst_val = float('inf')  # Initialize worst value to infinity (seeking minimum)\n",
    "    # --- END MODIFICATION ---\n",
    "\n",
    "    all_vals = []\n",
    "    found_baseline = False # Flag to check if baseline exists\n",
    "\n",
    "    for exp, hist in histories.items():\n",
    "\n",
    "        if exp == BASE_EXPERIMENT:\n",
    "            found_baseline = True # Mark baseline as found\n",
    "            continue # Skip baseline for min/max/avg calculation for now\n",
    "\n",
    "        # Ensure the metric exists in the history for this experiment\n",
    "        if METRIC not in hist:\n",
    "            print(f\"Warning: Metric '{METRIC}' not found in history for experiment '{exp}'. Skipping.\")\n",
    "            continue\n",
    "        if not hist[METRIC]: # Skip if metric list is empty\n",
    "             print(f\"Warning: Metric list for '{METRIC}' is empty for experiment '{exp}'. Skipping.\")\n",
    "             continue\n",
    "\n",
    "        # Safely access meta info\n",
    "        if exp not in meta_info:\n",
    "             print(f\"Warning: Meta info not found for experiment '{exp}'. Skipping for plotting details.\")\n",
    "             continue # Skip if no meta info for this experiment\n",
    "        dataset, n_gen, used_gen, n_real, n_fake = meta_info[exp].values()\n",
    "\n",
    "        n_gen_int_str = str(used_gen) # Use used_gen which seems to be the specific generator index string\n",
    "\n",
    "        # Plot individual run (use a try-except for robustness if needed)\n",
    "        try:\n",
    "            # Define color - adjust alpha or calculation if needed\n",
    "            color_val = np.clip((int(n_gen_int_str)+1) / (int(n_gen)), 0, 1) if int(n_gen) > 1 else 0.5\n",
    "            # Example color: using a blue gradient, lighter for lower index gen\n",
    "            run_color = (0.1, 0.2, color_val * 0.8 + 0.2, 0.25) # Light blueish gradient with alpha\n",
    "            plt.plot(\n",
    "                hist[METRIC],\n",
    "                color=run_color # Example: use a colormap if preferred\n",
    "            )\n",
    "        except ValueError:\n",
    "             print(f\"Warning: Could not parse used_gen '{n_gen_int_str}' or n_gen '{n_gen}' as integer for experiment '{exp}'. Skipping color calculation.\")\n",
    "             plt.plot(hist[METRIC], color=(0.5, 0.5, 0.5, 0.25)) # Default light grey\n",
    "        except IndexError:\n",
    "             print(f\"Warning: Issue accessing meta_info values for experiment '{exp}'.\")\n",
    "             plt.plot(hist[METRIC], color=(0.5, 0.5, 0.5, 0.25)) # Default light grey\n",
    "\n",
    "\n",
    "        all_vals.append(hist[METRIC])\n",
    "        current_final_val = hist[METRIC][-1]\n",
    "\n",
    "        # --- MODIFIED: Update Best/Worst Logic ---\n",
    "        if lower_is_better: # Handling val_loss (lower is better)\n",
    "            # Update best run (lowest final value)\n",
    "            if current_final_val < best_val:\n",
    "                best_val = current_final_val\n",
    "                best_run_key = exp\n",
    "                best_run_hist = hist[METRIC]\n",
    "            # Update worst run (highest final value)\n",
    "            if current_final_val > worst_val:\n",
    "                worst_val = current_final_val\n",
    "                worst_run_key = exp\n",
    "                worst_run_hist = hist[METRIC]\n",
    "        else: # Handling accuracy, f1, etc. (higher is better)\n",
    "            # Update best run (highest final value)\n",
    "            if current_final_val > best_val:\n",
    "                best_val = current_final_val\n",
    "                best_run_key = exp\n",
    "                best_run_hist = hist[METRIC]\n",
    "            # Update worst run (lowest final value)\n",
    "            if current_final_val < worst_val:\n",
    "                worst_val = current_final_val\n",
    "                worst_run_key = exp\n",
    "                worst_run_hist = hist[METRIC]\n",
    "        # --- END MODIFICATION ---\n",
    "\n",
    "    if not all_vals:\n",
    "        print(f\"Error: No valid data found for metric '{METRIC}' in the provided histories (excluding baseline). Cannot generate plot.\")\n",
    "        plt.close() # Close the empty figure\n",
    "        return\n",
    "\n",
    "    # Pad shorter histories for averaging/median calculation\n",
    "    try:\n",
    "        max_len = max(map(len, all_vals))\n",
    "        # Ensure padding value is appropriate (NaN for numerical data)\n",
    "        all_vals_padded = [np.pad(np.array(a, dtype=float), (0, max_len - len(a)), mode='constant', constant_values=np.nan) for a in all_vals]\n",
    "\n",
    "        # Calculate average and median, ignoring NaNs\n",
    "        avg = np.nanmean(all_vals_padded, axis=0)\n",
    "        med = np.nanmedian(all_vals_padded, axis=0)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error during padding or aggregation: {e}. Check data types in metric lists.\")\n",
    "        plt.close()\n",
    "        return\n",
    "\n",
    "\n",
    "    # CUD color palette\n",
    "    color_worst = '#D55E00' # Rust (worst performance)\n",
    "    color_best = '#009E73'  # Teal (best performance)\n",
    "    color_avg = '#0072B2'  # Blue (average)\n",
    "    color_med = '#E69F00'  # Golden (median)\n",
    "    color_base = '#000000' # Black for baseline\n",
    "\n",
    "    # Plot worst run if found\n",
    "    if worst_run_key and worst_run_hist:\n",
    "        dataset_w, n_gen_w, used_gen_w, n_real_w, n_fake_w = meta_info.get(worst_run_key, [\"N/A\"]*5) # Default if key missing\n",
    "        # --- MODIFIED: Labeling ---\n",
    "        worst_label = f\"Worst ({'Max' if lower_is_better else 'Min'} {METRIC}), gen: {used_gen_w}, N-real: {n_real_w}, N-fake: {n_fake_w}\"\n",
    "        plt.plot(worst_run_hist, color=color_worst, linewidth=2, label=worst_label)\n",
    "    else:\n",
    "         print(\"Warning: Could not determine the worst run.\")\n",
    "\n",
    "\n",
    "    # Plot best run if found\n",
    "    if best_run_key and best_run_hist:\n",
    "        dataset_b, n_gen_b, used_gen_b, n_real_b, n_fake_b = meta_info.get(best_run_key, [\"N/A\"]*5) # Default if key missing\n",
    "         # --- MODIFIED: Labeling ---\n",
    "        best_label = f\"Best ({'Min' if lower_is_better else 'Max'} {METRIC}), gen: {used_gen_b}, N-real: {n_real_b}, N-fake: {n_fake_b}\"\n",
    "        plt.plot(best_run_hist, color=color_best, linewidth=2, label=best_label)\n",
    "    else:\n",
    "        print(\"Warning: Could not determine the best run.\")\n",
    "\n",
    "    # Plot average\n",
    "    plt.plot(avg, color=color_avg, linewidth=2, label=\"Average\")\n",
    "\n",
    "    # Plot median\n",
    "    plt.plot(med, color=color_med, linewidth=2, linestyle='--', label=\"Median\")\n",
    "\n",
    "    # Plot baseline if it was found and has the metric\n",
    "    if found_baseline and BASE_EXPERIMENT in histories and METRIC in histories[BASE_EXPERIMENT] and histories[BASE_EXPERIMENT][METRIC]:\n",
    "        plt.plot(histories[BASE_EXPERIMENT][METRIC], color=color_base, linewidth=2.5, linestyle=':', label='Baseline')\n",
    "    elif not found_baseline:\n",
    "         print(f\"Warning: Baseline experiment '{BASE_EXPERIMENT}' not found in histories.\")\n",
    "    else:\n",
    "         print(f\"Warning: Metric '{METRIC}' not found or empty in baseline history '{BASE_EXPERIMENT}'.\")\n",
    "\n",
    "\n",
    "    # --- MODIFIED: Dynamic Title ---\n",
    "    # Extract dataset name from the first valid meta_info entry if possible\n",
    "    try:\n",
    "        first_valid_key = next((k for k in histories if k != BASE_EXPERIMENT and k in meta_info), None)\n",
    "        plot_dataset_name = meta_info[first_valid_key]['dataset'] if first_valid_key else \"Unknown Dataset\"\n",
    "    except:\n",
    "        plot_dataset_name = \"Unknown Dataset\" # Fallback\n",
    "\n",
    "    plt.title(f\"{METRIC.replace('_', ' ').title()} - Dataset: {plot_dataset_name}, N-Gen: {target_gen}\")\n",
    "    # --- END MODIFICATION ---\n",
    "\n",
    "    plt.xlabel(\"Epoch\") # Add xlabel\n",
    "    plt.ylabel(METRIC.replace('_', ' ').title()) # Add ylabel\n",
    "    plt.legend(fontsize='small') # Adjust legend size if needed\n",
    "    plt.grid(True, linestyle='--', alpha=0.6) # Add grid for readability\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    if show:\n",
    "        print(\"Displaying plot...\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        try:\n",
    "            save_path.parent.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"Plot saved to {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving plot to {save_path}: {e}\")\n",
    "\n",
    "    plt.close() # Close the figure to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4abf936-5f67-42da-91f8-7ac6aff06740",
   "metadata": {},
   "source": [
    "### NOTE: \n",
    "there are only experiments with 3, 5, 7, 10 generators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a2e66e-e3aa-46b1-9a33-6ce836b928b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT METRIC: val_accuracy\n",
      "CURRENT GENERATOR: 3\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_accuracy_MADGAN_FASHION_n_gen_3_all.png\n",
      "CURRENT GENERATOR: 5\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_accuracy_MADGAN_FASHION_n_gen_5_all.png\n",
      "CURRENT GENERATOR: 7\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_accuracy_MADGAN_FASHION_n_gen_7_all.png\n",
      "CURRENT GENERATOR: 10\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_accuracy_MADGAN_FASHION_n_gen_10_all.png\n",
      "CURRENT METRIC: val_f1_score\n",
      "CURRENT GENERATOR: 3\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_f1_score_MADGAN_FASHION_n_gen_3_all.png\n",
      "CURRENT GENERATOR: 5\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_f1_score_MADGAN_FASHION_n_gen_5_all.png\n",
      "CURRENT GENERATOR: 7\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_f1_score_MADGAN_FASHION_n_gen_7_all.png\n",
      "CURRENT GENERATOR: 10\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_f1_score_MADGAN_FASHION_n_gen_10_all.png\n",
      "CURRENT METRIC: val_loss\n",
      "CURRENT GENERATOR: 3\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_loss_MADGAN_FASHION_n_gen_3_all.png\n",
      "CURRENT GENERATOR: 5\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_loss_MADGAN_FASHION_n_gen_5_all.png\n",
      "CURRENT GENERATOR: 7\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_loss_MADGAN_FASHION_n_gen_7_all.png\n",
      "CURRENT GENERATOR: 10\n",
      "Plot saved to C:\\Users\\NiXoN\\Desktop\\_thesis\\mad_gan_thesis\\latex\\master_thesis\\abb\\strat_classifier_performance\\val_loss_MADGAN_FASHION_n_gen_10_all.png\n"
     ]
    }
   ],
   "source": [
    "# load all histories: \n",
    "\n",
    "experiments_by_used_gen = {}\n",
    "\n",
    "histories = {}\n",
    "meta_info = {}\n",
    "\n",
    "for METRIC in metrics:\n",
    "    print(f\"CURRENT METRIC: {METRIC}\")\n",
    "    for target_gen in [3, 5, 7, 10,]:\n",
    "    \n",
    "        print(f\"CURRENT GENERATOR: {target_gen}\")\n",
    "    \n",
    "        for exp in experiments: \n",
    "        \n",
    "            meta = extract_info_from_experiment_name(exp)\n",
    "    \n",
    "        \n",
    "            if meta['n_gen'] == str(target_gen):\n",
    "                history = np.load(Path(strat_exp_path) / exp / 'training_history.npy', allow_pickle=True).item()\n",
    "                histories[exp] = history\n",
    "                meta_info[exp] = meta\n",
    "                \n",
    "            else: \n",
    "                continue\n",
    "                \n",
    "        histories = sort_dict_based_on_n_real_images(histories)\n",
    "        meta_info = sort_dict_based_on_n_real_images(meta_info)\n",
    "    \n",
    "        exp = BASE_EXPERIMENT        \n",
    "        meta = extract_info_from_experiment_name(exp)\n",
    "    \n",
    "        history = np.load(Path(strat_exp_path) / exp / 'training_history.npy', allow_pickle=True).item()\n",
    "        histories[exp] = history\n",
    "        meta_info[exp] = meta\n",
    "    \n",
    "        if histories:\n",
    "            plot_history_strat_classifiers(\n",
    "                histories, \n",
    "                meta_info, \n",
    "                Path(\"C:\\\\Users\\\\NiXoN\\\\Desktop\\\\_thesis\\\\mad_gan_thesis\\\\latex\\\\master_thesis\\\\abb\\\\strat_classifier_performance\") / f\"{METRIC}_{TYPE}_{DATASET}_n_gen_{target_gen}_all.png\",    \n",
    "                target_gen,\n",
    "                METRIC\n",
    "            )\n",
    "        histories = {}\n",
    "        meta_info = {}\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58628a01-3412-405d-9120-90a1cf5c3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9fcb1-9913-47b9-9f77-df67122efc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
