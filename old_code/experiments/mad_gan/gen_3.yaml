general:
  experiment_name: "mad_gan_experiment_2"
  seed: 42
  device: "cuda"

model:
  num_generators: &num_generators 3
  num_classes: &num_classes 10
  latent_dim: &latent_dim 256
  generators:
    num_generators: *num_generators
    latent_dim: *latent_dim
    shared_layers:
      - type: "Dense"
        units: 12544  # 7*7*256
        bias: False
        input_shape: 
          - *latent_dim
      - type: "BatchNormalization"
      - type: "LeakyReLU"
      - type: "Reshape"
        values: 
          - 7
          - 7
          - *latent_dim
      - type: "Conv2DTranspose"
        units: 128
        filter: 
          - 5
          - 5
        stride: 
          - 1
          - 1
        padding: "same"
        bias: False
      - type: "BatchNormalization"
      - type: "LeakyReLU"
      - type: "Conv2DTranspose"
        units: 64
        filter: 
          - 5
          - 5
        stride: 
          - 2
          - 2
        padding: "same"
        bias: False 
      - type: "BatchNormalization"
      - type: "LeakyReLU"
    separate_layers:
      before: []
      after:
        - type: "Conv2DTranspose"
          units: 1
          filter: 
            - 5
            - 5
          stride: 
            - 2
            - 2
          padding: "same"
          bias: False
          activation: "tanh"

  discriminator:
    layers:
      #- type: "Input"
      #  shape: [28, 28, 1]  # The input shape is specified here
      - type: "Conv2D"
        units: 64
        filter: [5, 5]
        stride: [2, 2]
        padding: "same"
        input_shape: [28, 28, 1]  # Specifying the input shape for the first Conv2D layer
      - type: "LeakyReLU"
      - type: "Dropout"
        rate: 0.3
      - type: "Conv2D"
        units: 128
        filter: [5, 5]
        stride: [2, 2]
        padding: "same"
      - type: "LeakyReLU"
      - type: "Dropout"
        rate: 0.3
      - type: "Flatten"
      - type: "Dense"
        units: 6  # Replace this with actual number of generators plus one
        activation: "softmax"
        bias: True
        

# Uncomment and complete the following sections if needed

# training:
#   batch_size: 64
#   epochs: 200
#   learning_rate: 0.0002
#   betas: 
#     - 0.5
#     - 0.999
#   checkpoint_interval: 10
#   save_model: true
#   log_interval: 100
# 
# data:
#   dataset_name: "MNIST"
#   data_path: "./data"
#   download: true
