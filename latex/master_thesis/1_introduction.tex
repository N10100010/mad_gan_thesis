\section{Introduction and Motivation}\label{introduction_and_motivation}
\pagestyle{fancy}
%\setcounter{page}{1}
\textit{Generative Adversarial Networks} (GANs) \cite{goodfellow2014generativeadversarialnetworks} and their variants revolutionized the field of computer vision in the year of 2014, enabling advacements in multiple areas of generating data. From \textit{Text to Image Synthesis} \cite{reed2016generativeadversarialtextimage}, \textit{Image Translation} \cite{isola2018imagetoimagetranslationconditionaladversarial}, \textit{Super Resolution} \cite{ledig2017photorealisticsingleimagesuperresolution}, \textit{Image Inpainting} \cite{pathak2016contextencodersfeaturelearning}, \textit{Style Transfer} \cite{wang2023multimodalityguidedimagestyletransfer} to \textit{Data Augmentation} \cite{shorten2019survey}, GANs have been used in a variety of applications.

% TODO: MORE REFERENCES HERE? - see mad gan main paper )(introduction) for more
The idea of using GANs for \textit{Generative Data Augmentation} (GDA) has already been applied successfully, e.g.: in computer vision \cite{Li2025comprehensivesurvedeepimages}, \cite{biswas2023generativeadversarialnetworksdata} or for creating music \cite{ji2020comprehensivesurveydeepmusic}. Especially the former survey \textit{A Comprehensive Survey of Image Generation Models Based on Deep Learning} has, along \textit{Variational Auto Encoders} (VAEs), a dedicated focus on GANs. Despite these achievements, in practice, GANs suffer from several challenges, complicating the training and inference process:

\begin{itemize}\label{problems_of_gans}
    \setlength{\itemsep}{-5pt}
    \item Mode Collapse
    \item Lack of inter-class Diversity
    \item Failure to Converge
    \item Vanishing Gradients \& Unstable Gradients
    \item Imbalance between Generator- and Discriminator Model
\end{itemize}

This thesis investigates the potential of using GANs - specifically \textit{Multi-Agent Diverse Generative Adversarial Networks} (MADGANs) \cite{ghosh2018madgan} - for Generative Data Augmentation. MADGANs aim to aid the first two of the afore mentioned in particular: Mode Collapse and Loss of inter-class Diversity. They, along other modifications, "\textit{propose to modify the objective function of the discriminator, in which, along with finding the real and the fake samples, the discriminator also has to correctly predict the generator that generated the given fake sample.}" \cite{ghosh2018madgan}. The goal of this adjustment of the discriminator is, that the discriminator has to push the generators towards distinct identifiable modes. While various strategies have been proposed to addrese mode collapse and inter-class diversity MADGANs explicitly enforce mode separation by introduction of multiple generators and the adjusted discriminator objective. This makes them particularly promising for GDA, as diverse samples and clear distinction of modes is crucial for training robust classifiers. In their paper, they experimentally show, that their architectural adjustment of GANs is generally capable of giving providing assistance for the first two of the mentioned problems.

The experiments in this work are structured into three major parts.

\paragraph{Set 1: Training and Analysis of GANs}  \label{thesis_goal_1}
The first set trains multiple variations of GANs, explicitly \textit{Deep Convolutional GANs} (DCGANs), \textit{Conditional GANs} (cGANs) and the afore introduced MADGANs, in addition to an adapted conditionalized version called \textit{Conditional Multi-Agent Diverse GANs} (cMADGANs) \ref{theoretical_cmadgan}. Here, the quality of the resulting images after training will be scored by the \textit{Fréchet Inception Distance} (FID) \cite{heusel2018ganstrainedtimescaleupdate} and the \textit{Inception Score} (IS) \cite{salimans2016improvedtechniquestraininggans}.

\paragraph{Set 2: Generating and Classifying Unlabeled Images}  \label{thesis_goal_2}
The second set uses the afore trained generative models to create images. Images without labels—images originating from MADGANs—will be classified using auxiliary classifiers trained with traditional data augmentation techniques.
The second instance the trained generative models are utilized to generate at least $6.000$ images per class. Since some architectures not non-conditional, pre-trained classifiers will be used to classify images. Specifically, data resulting from DCGANs and MADGANs have to be classified and given labels. 

\paragraph{Set 3: Training and Evaluating Classifiers}  \label{thesis_goal_3}
The third and most important set of experiments train classifiers using the generated and labeled samples. For this, stratified classifiers with different ratios of real to fake images are trained and evaluated on the respective validation set. These experiments are split into two scenarios: Replacement- and Expansion Scenarios. Their classification performance will be assessed using the \textit{F1 Score}.  \\

\noindent All of the above described is executed on the following datasets:
\begin{itemize}\label{used_datasets}
    \setlength{\itemsep}{-5pt}
    \item MNIST \cite{lecun2010mnist}
    \item Fashion MNIST \cite{xiao2017fashionmnist}
    %\item CIFAR10 \cite{Krizhevsky2009learning}
\end{itemize}


\paragraph{Aim of the Thesis}\label{aim_of_the_thesis}
This thesis evaluates the effectiveness of Multi-Agent Diverse GANs (MADGAN) for Generative Data Augmentation. First, the quality of generated samples is compared to those produced by a Deep Convolutional- and Conditional GAN. Further, a conditional adaptation of the MADGAN architecture is introduced and tested alongside already established methods. The quality of the resulting images is then evaluated utilizing the \textit{InceptionV3} model to calculate the Inception Score and FID of those images. Next, the sets of generated images are used to replace and alter training datasets for classifiers. The performances of the different classifiers are assessed by the F1 score. These sets of experiments are compared against traditional augmentations techniques, such as flipping, rotating and adding noise to the images, which serve as a minimum baseline. 

\noindent
With this experimental succession, this thesis studies the effect of the MADGAN-based data augmentation for subsequent classifiers, together with its conditionalized counterpart and comparing their performances against established traditional and generative augmentation techniques. 


\newpage
