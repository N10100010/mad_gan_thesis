\section{Experiments Setup}\label{body_experiments_setup}

\subsection{Preliminary Remarks}\label{body_prelim}
This chapter outlines general remarks relevant to the subsequent experiment chapters (\ref{body_experiments_setup}, \ref{body_experiments_results}).

\subsubsection{Datasets}

\begin{table}[H]
    \centering
    \caption{Summary of commonly used benchmark datasets for image classification.}
    \label{tab:dataset_summary}
    % Adjusted column widths: l{1.8cm} and p{6cm}
    \begin{tabular}{|p{1.8cm}|c|c|c|p{6cm}|} % <-- Adjusted widths here
        \hline
        \textbf{Dataset} & \textbf{Samples} & \textbf{Image Size} & \textbf{Channels} & \textbf{Description} \\
        \hline
        MNIST & 70,000 & $28 \times 28$ & 1 & Contains grayscale images of handwritten digits (0â€“9). A widely used benchmark for evaluating fundamental classification algorithms. \\
        \hline
        Fashion-MNIST & 70,000 & $28 \times 28$ & 1 & Drop-in replacement for MNIST with grayscale images of clothing items. Offers increased complexity and class variability, better reflecting real-world visual tasks. \\
        \hline
        CIFAR-10 & 60,000 & $32 \times 32$ & 3 & RGB images of real-world objects such as vehicles and animals. Frequently used for evaluating deep learning models under complex conditions with background noise and intra-class variation. While the dataset itself is static, data augmentation is commonly applied during training. \\
        \hline
    \end{tabular}
\end{table}



\subsubsection{GAN: Architecture, Training and Data Augmentation}

\noindent\textbf{Architecture of the GANs}
In all experiments involving GAN models and their derivatives, the same network architecture has been employed for the \textit{MNIST} and \textit{Fashion MNIST} datasets. For initial experiments targeting the standard \textit{CIFAR-10} dataset (32, 32, 3), deeper architectures were utilized for both the generator and discriminator networks to account for the increased complexity of the data. However, for a specific set of experiments detailed in Section [todo: reference the correct section], where the CIFAR-10 dataset was modified (28, 28, 1) to facilitate analysis, architectures comparable to those used for MNIST/Fashion-MNIST were employed. These proofed to result in mostly stable training. The specific architecture relevant to each experiment will be reiterated in its respective section.\\

\noindent\textbf{Training}
For training all GAN-based models, including DCGAN, cGAN, MADGAN and cMADGAN, the \textit{Adam} optimizer has been utilized. The learning rate follows an exponentially decaying schedule throughout the training process.\\

\noindent\textbf{Data Augmentation}\label{body_experiment_dataaugmentation}
To increase the diversity of the training data for both generator and discriminator models, several traditional augmentation techniques have been applied. These include horizontal flips, brightness and contrast adjustments, and the addition of Gaussian noise.
Horizontal flips are applied with a probability of \(50\%\), except for the \textit{MNIST} dataset, where flips are omitted due to the semantic relevance of digit orientation. Brightness and contrast adjustments are always applied within a uniform range of \([-0.1, 0.1]\). Gaussian noise is added by sampling from a normal distribution with mean \(0\) and standard deviation \(0.05\). Finally, the augmented images are clipped to the valid value range of \([-1, 1]\).\\

\subsubsection{Labeling unconditioned data}\label{body_experiment_labeling_data}
Due to the fact, that multiple experiment using unconditioned GANs were executed (todo: ref to the experiments), many images have been created with no corresponding label to them. To classify the unlabeled data, simple CNN classifiers, with adequate TDA. The applied augemntations techniques are the as follows: horizontal- and vertical shift by 0.1 relativ to the absolute size of the image, rotation of up to 15 degree and vertical flipping. As afore mentioned, flipping images along the vertical axes is omitted for the MNIST dataset, due to semantical invalidity. Graphical depictions of the classiers used can be found in the appendix (\ref{appendix_classifiers}).\\


\subsubsection{Utilization of InceptionV3 for FID and IS}\label{body_experiment_inception_model}
It is crucial to note that the significant differences between the ImageNet domain (high-resolution, color, 1000 object classes) and datasets commonly used in GAN research like MNIST, Fashion-MNIST (low-resolution, grayscale), or CIFAR-10 (low-resolution, color, 10 simpler classes) represent a substantial domain gap \ref{theoretical_inception_model_limitaitions}. This gap may limit the effectiveness or absolute interpretability of InceptionV3-based scores for these specific datasets. Furthermore, due to the sensitivity of these scores to implementation details (e.g., image resizing methods, specific InceptionV3 weight versions), a direct comparison of scores calculated here to those from external literature is generally unreliable unless the evaluation methodology is verified to be identical. Therefore, within this thesis, IS and FID scores are primarily utilized for relative comparisons between the different models and experiments conducted herein, rather than for absolute benchmarking against potentially disparate external results. This context warrants careful consideration when analyzing the experimental outcomes presented later.


\subsection{Experimental Succession}\label{body_experiment_succession}
Generally, the succession of experiments follows a strict pattern that can be described in the following order:
\begin{enumerate}
    \item Train the current GAN model and track its performance via predefined metrics (IS, FID).
    \item Using the resulting generative model, generate fake samples, such that, for every class in the original dataset, \(5000\) images per class are created.
    \begin{itemize}
        \item If the samples originate from an unconditioned generative model, classify them using a pretrained classifiers \ref{body_experiment_labeling_data}.
    \end{itemize}
    \item Train the same classifier architecture, depending on the dataset, with different ratios of real and fake samples.
    \item Evaluate the performance of the classification model using predefined metrics (todo: reference the correct following section)
\end{enumerate}

\subsection{Hardware and Software Environment}

\subsubsection{Hardware}
All models trained in the context of this thesis were trained utilizing the \textit{Deeplearning Cluster} provided by the \textit{Hochschule der Medien - Stuttgart}. The cluster provides 8 nodes that with dedicated graphics cards supporting the \textit{CUDA} framework. The specific machines deployed in the cluster can be seen here \href{https://deeplearn.pages.mi.hdm-stuttgart.de/docs/}{Deeplearn cluster Documentation}\footnote{Link to the documentation for print versions: \url{https://deeplearn.pages.mi.hdm-stuttgart.de/docs/}.}.

\subsubsection{Software}
The code for the experiments was developed with the programming language python, using version \(3.9\). Models are based on the tensorflow ecosystem. The exact packages and their respective version can be found here \href{https://github.com/N10100010/mad_gan_thesis/blob/main/code/server_env.yml}{Aanconda environment}\footnote{Link to the environment file for print versions: \url{https://github.com/N10100010/mad_gan_thesis/blob/main/code/server_env.yml}.}.



\newpage
