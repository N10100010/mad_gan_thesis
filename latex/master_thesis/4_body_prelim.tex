\section{Preliminary Remarks}\label{body_prelim}


%##########################################
% Exlain: 
% architecture for madgans for mnist/fashion and cifar
% PONIT OUT THAT MNIST AND FASHION ARE THE SAME ARCHITECTURE AND HOW THEY DIFFER TO THE ONE USED FOR CIFAR

% EXPLAIN THE ARCHITEXTURE FOR CONDGAN FOR MNIST/FASHION AND CIFAR

%% --> POINT OUT THAT ALL THE ABOVE HAD TRADITIONAL DATA AUGMENTATION TO AUGMENT TRAINING DATA
%% ----> WHICH ONES EXACTLY? 



% EXPLAIN HOW THE FID AND IS SCORES ARE CALCULATED
% --> MENTION THAT EXPERIMENTS HAVE BEEN MADE TO USE SELF-TRAINED CLASSIFIERS/FREATURE-EXTRACTORS FOR THE MNIST AND FASHION DATASETS AND WHY THE DESCICION WAS MADE AGAINST THIS APPROACH -- SINCE ITS ONLY SELF-REFERENTIOAL AND SELF COMPARING, IT IS FINE TO USE THE INCEPTIONV3 MODEL FOR ALL DATASETS. 

% EXPLAIN HOW THE DATA FOR EACH CLASSIFIER WAS GENERATED 
% EXPLAIN THE CLASSIFIERS THEMSELVES 
% 
%##########################################

%##########################################
% How are the fid and is calculated? 
% Explain for all three datasets
%##########################################

%##########################################
% GAN TRAINING: whenever possible (excluding MNSIt), traditional data augmentation techniques: \ref{traditional_data_augmentation} have been applied to train the gans (all gans)
%##########################################


%##########################################
% 
%##########################################






%# EXAMPLE OF FORMULA
%# \begin{quotation}
%# \centering
%#    \( A_t = \delta_t + (\gamma \lambda)\delta_{t+1} + ... + (\gamma \lambda)^{T-t+1} \delta_{T-1} \)
%# \end{quotation}












\newpage
