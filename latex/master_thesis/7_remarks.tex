\section{Remarks} \label{chapter_remarks}
This section shall serve ideas that, with the implemented frameworks and trained models, could further be analyzed. These ideas have been omitted, to stick to the scope of this thesis. 

\subsection{Connection between Generator Index and used Ratio to Classifier Performance}
\noindent \noindent With the current design of the study, especially for the multi-generator architectures, some granular insights into individual generator contributions to GDA performance are not fully elaborated in the main results. This is primarily due to the sheer volume of data from individual multi-generator architectures and the substantial number of corresponding classifiers trained. To illustrate the scale, the experimental workflow (as detailed in Section \ref{body_experiment_succession}) required evaluating both Replacement and Expansion GDA scenarios using the synthetic samples produced by each of the $K$ generators independently. Since each of these scenarios involved testing six distinct data compositions (e.g., varying ratios of real to synthetic data), a multi-generator model with $K$ components led to $K \times 6$ classifiers being trained for the Replacement experiments, and an equivalent number for the Expansion experiments\footnote{Recall that both Expansion and Replacement scenarios included six different ratios.}. Consequently, in cases with $K=10$ generators, figures depicting the results for just one scenario, such as Replacement, would ideally display $10 \text{ generators} \times 6 \text{ configurations} = 60$ distinct learning curves, leading to very dense visualizations (exemplified in Figures \ref{fig:app_strat_class_performance_replacement__val_f1__10__example_used_1} and \ref{fig:app_strat_class_performance_expansion__val_f1__10__example_used_1}). A significant amount of time has been invested, trying to add information about the generators' index to the graphs, visually connecting the generator creating the samples with the classifier using said data. With the Figures already containing such a high number of graphs, the decision was made to only reduce the opacity of the graphs, to indicate a trend via overlapping graphs, ultimately resulting in a darker visual representation. This is especially prominent in the second linked figure.

\subsection{Distinction of Modes}
\noindent A big advantage inherent to the MADGAN architecture is the encouraged diversity and the enforced differentiation of modes, through the adjusted generator-identification objective of the discriminator \ref{theoretical_madgan_math}. Following those implications, if successful, the generators should focus on a specific subset of modes. In case of the MNIST dataset, this may result in $N$, potentially overlapping subsets of generator outputs. It is imaginable that one specific generator may be better at creating samples for the classes \([0, 3, 5, 8]\) and another is better creating samples for \([1, 4, 7]\). 
Each classifier was used to create a classification report, stating its capabilities to classify each class separately\footnote{For this, the classification report from \textit{scikit-learn} was used. See: \url{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html}.}. Therefore, the information about which generator created images best for a certain class is already present, but open for analysis.

\newpage